{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavanakodali5/ObjectDectection-IIITH/blob/main/African_Wildlife.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Google Colab Setup ---\n",
        "# This section prepares your Colab environment.\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "# This allows you to save your trained models and results persistently,\n",
        "# so you don't lose them when your Colab session ends.\n",
        "# You'll be prompted to authorize Google Drive access.\n",
        "from google.colab import drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted at /content/drive\")\n",
        "\n",
        "# Define the path where you want to save your results within Google Drive\n",
        "# It's good practice to create a specific folder for your project.\n",
        "DRIVE_PROJECT_PATH = '/content/drive/MyDrive/YOLOv8_African_Wildlife_Results'\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "import os\n",
        "os.makedirs(DRIVE_PROJECT_PATH, exist_ok=True)\n",
        "print(f\"Results will be saved to: {DRIVE_PROJECT_PATH}\")\n",
        "\n",
        "\n",
        "# 2. Install Ultralytics YOLOv8\n",
        "# This command installs the necessary library for YOLOv8.\n",
        "# The `-q` flag keeps the output quiet.\n",
        "print(\"\\nInstalling Ultralytics YOLOv8...\")\n",
        "!pip install -q ultralytics\n",
        "print(\"Ultralytics YOLOv8 installed.\")\n",
        "\n",
        "# 3. Change directory to /content\n",
        "# This is a common and convenient location in Colab for temporary files and datasets.\n",
        "%cd /content\n",
        "print(\"\\nChanged current directory to /content\")\n",
        "\n",
        "# 4. Download the African Wildlife Dataset YAML file\n",
        "# This YAML file contains the configuration for the African Wildlife dataset,\n",
        "# including instructions for Ultralytics to automatically download the actual image data.\n",
        "print(\"Downloading dataset configuration file 'african-wildlife.yaml'...\")\n",
        "!wget -q https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/datasets/african-wildlife.yaml\n",
        "print(\"'african-wildlife.yaml' downloaded.\")\n",
        "\n",
        "# --- YOLOv8 Training Script ---\n",
        "# This is the core script for training your object detection model.\n",
        "\n",
        "# Import the YOLO class from the ultralytics library\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import shutil # For copying files\n",
        "\n",
        "# --- Configuration ---\n",
        "# Set the desired number of training epochs.\n",
        "# The user requested anywhere between 10 to 25 epochs. We'll use 20 for this example.\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# Define the path to your dataset's YAML file.\n",
        "# We've already downloaded 'african-wildlife.yaml' to /content.\n",
        "DATASET_YAML_PATH = 'african-wildlife.yaml'\n",
        "\n",
        "# Define the model to use. 'yolov8n.pt' is the smallest and fastest model.\n",
        "# You can try 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', or 'yolov8x.pt' for better accuracy\n",
        "# but slower training/inference. Ultralytics will download this model automatically if not found.\n",
        "MODEL_NAME = 'yolov8n.pt'\n",
        "\n",
        "# Define the image size for training. 640 is a common default for YOLOv8.\n",
        "IMAGE_SIZE = 640\n",
        "\n",
        "# --- Model Training Function ---\n",
        "def train_yolov8_model():\n",
        "    \"\"\"\n",
        "    Loads a YOLOv8 model, trains it on the African Wildlife dataset,\n",
        "    and saves the training results.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Starting YOLOv8 training for {MODEL_NAME} ---\")\n",
        "    print(f\"Dataset YAML: {DATASET_YAML_PATH}\")\n",
        "    print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "    print(f\"Image Size: {IMAGE_SIZE}\")\n",
        "\n",
        "    # Verify that the dataset YAML file exists before proceeding.\n",
        "    if not os.path.exists(DATASET_YAML_PATH):\n",
        "        print(f\"Error: Dataset YAML file not found at '{DATASET_YAML_PATH}'\")\n",
        "        print(\"Please ensure it was downloaded correctly in the previous steps.\")\n",
        "        print(\"Refer to: https://docs.ultralytics.com/datasets/detect/african-wildlife/#dataset-yaml\")\n",
        "        return\n",
        "\n",
        "    # Inform the user where the dataset is expected to be downloaded by Ultralytics\n",
        "    expected_dataset_path = \"/content/datasets/african-wildlife\"\n",
        "    print(f\"The African Wildlife dataset will be automatically downloaded and extracted to: {expected_dataset_path}\")\n",
        "\n",
        "    try:\n",
        "        # Load a pre-trained YOLOv8 model.\n",
        "        # This will automatically download the weights if they are not already present locally.\n",
        "        model = YOLO(MODEL_NAME)\n",
        "        print(f\"Model '{MODEL_NAME}' loaded successfully.\")\n",
        "\n",
        "        # Train the model.\n",
        "        # Ultralytics will save results to a 'runs' directory in the current working directory,\n",
        "        # which is still /content at this point.\n",
        "        results = model.train(data=DATASET_YAML_PATH, epochs=NUM_EPOCHS, imgsz=IMAGE_SIZE)\n",
        "\n",
        "        print(\"\\n--- Training complete! ---\")\n",
        "        # Identify the training run's output directory\n",
        "        local_runs_dir = '/content/runs/detect'\n",
        "        # Get the latest run folder (e.g., 'train', 'train1', 'train2')\n",
        "        latest_run_folder = sorted([d for d in os.listdir(local_runs_dir) if os.path.isdir(os.path.join(local_runs_dir, d))])[-1]\n",
        "        source_results_path = os.path.join(local_runs_dir, latest_run_folder)\n",
        "\n",
        "        print(f\"Results initially saved locally to: {source_results_path}\")\n",
        "\n",
        "        # Copy results to Google Drive\n",
        "        destination_results_path = os.path.join(DRIVE_PROJECT_PATH, latest_run_folder)\n",
        "        print(f\"Copying results to Google Drive: {destination_results_path}...\")\n",
        "        shutil.copytree(source_results_path, destination_results_path)\n",
        "        print(\"Results successfully copied to Google Drive!\")\n",
        "\n",
        "        print(f\"You can find your results (graphs, best.pt model, etc.) here: {destination_results_path}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred during training or saving results: {e}\")\n",
        "        print(\"Please review the error message and ensure your Colab environment,\")\n",
        "        print(\"installations, and dataset configuration are correct. Also check Google Drive permissions.\")\n",
        "    finally:\n",
        "        # Always try to list the contents of the datasets directory\n",
        "        print(f\"\\n--- Verifying dataset directory contents ({expected_dataset_path}) ---\")\n",
        "        if os.path.exists(expected_dataset_path):\n",
        "            !ls -l {expected_dataset_path}\n",
        "        else:\n",
        "            print(f\"The dataset directory {expected_dataset_path} does not exist.\")\n",
        "            print(\"This indicates the dataset was likely not downloaded or extracted successfully during training.\")\n",
        "            print(\"Check the training output above for any download errors.\")\n",
        "\n",
        "\n",
        "# --- Execute Training ---\n",
        "# This ensures the training function runs when the script is executed.\n",
        "if __name__ == '__main__':\n",
        "    train_yolov8_model()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted at /content/drive\n",
            "Results will be saved to: /content/drive/MyDrive/YOLOv8_African_Wildlife_Results\n",
            "\n",
            "Installing Ultralytics YOLOv8...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUltralytics YOLOv8 installed.\n",
            "/content\n",
            "\n",
            "Changed current directory to /content\n",
            "Downloading dataset configuration file 'african-wildlife.yaml'...\n",
            "'african-wildlife.yaml' downloaded.\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\n",
            "--- Starting YOLOv8 training for yolov8n.pt ---\n",
            "Dataset YAML: african-wildlife.yaml\n",
            "Epochs: 20\n",
            "Image Size: 640\n",
            "The African Wildlife dataset will be automatically downloaded and extracted to: /content/datasets/african-wildlife\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 245MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'yolov8n.pt' loaded successfully.\n",
            "Ultralytics 8.3.155 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=african-wildlife.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "WARNING ⚠️ Dataset 'african-wildlife.yaml' images not found, missing path '/content/datasets/african-wildlife/valid/images'\n",
            "Downloading https://ultralytics.com/assets/african-wildlife.zip to '/content/datasets/african-wildlife.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100M/100M [00:00<00:00, 391MB/s] \n",
            "Unzipping /content/datasets/african-wildlife.zip to /content/datasets/african-wildlife...: 100%|██████████| 3008/3008 [00:00<00:00, 3186.83file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ✅ (1.5s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 100MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1223.7±464.2 MB/s, size: 54.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/african-wildlife/train/labels... 1052 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1052/1052 [00:00<00:00, 1692.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/african-wildlife/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 599.5±267.8 MB/s, size: 42.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/african-wildlife/valid/labels... 225 images, 0 backgrounds, 0 corrupt: 100%|██████████| 225/225 [00:00<00:00, 2081.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/african-wildlife/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20         0G     0.8264      2.202      1.204         45        640: 100%|██████████| 66/66 [15:24<00:00, 14.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:56<00:00,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.679       0.46      0.618      0.426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20         0G     0.9039      1.511      1.248         40        640: 100%|██████████| 66/66 [15:16<00:00, 13.89s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.795      0.643       0.73      0.477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20         0G     0.9421      1.456      1.264         56        640: 100%|██████████| 66/66 [15:18<00:00, 13.92s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.713      0.647      0.717       0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20         0G     0.9621      1.347      1.265         51        640: 100%|██████████| 66/66 [15:09<00:00, 13.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:53<00:00,  6.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.758       0.69      0.796      0.562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20         0G     0.9433      1.269      1.266         46        640: 100%|██████████| 66/66 [15:06<00:00, 13.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.777      0.585      0.696      0.445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20         0G     0.9069      1.172      1.248         52        640: 100%|██████████| 66/66 [15:07<00:00, 13.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379       0.85      0.741       0.85      0.602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20         0G     0.8923      1.098      1.231         41        640: 100%|██████████| 66/66 [15:08<00:00, 13.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.867       0.78      0.886      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20         0G     0.8618      1.015      1.196         49        640: 100%|██████████| 66/66 [15:05<00:00, 13.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379       0.85       0.78      0.878      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20         0G     0.8251     0.9689      1.188         53        640: 100%|██████████| 66/66 [15:12<00:00, 13.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.847      0.796      0.884      0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20         0G     0.8202      0.946      1.175         62        640: 100%|██████████| 66/66 [15:11<00:00, 13.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.916      0.843      0.911      0.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20         0G     0.7505     0.9212      1.142         18        640: 100%|██████████| 66/66 [15:04<00:00, 13.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.912      0.794      0.893       0.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20         0G     0.7247     0.8243       1.12         17        640: 100%|██████████| 66/66 [15:05<00:00, 13.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.862      0.833      0.899      0.686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20         0G     0.6924     0.7491      1.105         22        640: 100%|██████████| 66/66 [15:05<00:00, 13.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.919      0.853      0.928      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20         0G      0.671     0.6945      1.083         21        640: 100%|██████████| 66/66 [15:10<00:00, 13.79s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.869      0.829      0.908      0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20         0G     0.6449     0.6506      1.077         22        640: 100%|██████████| 66/66 [15:11<00:00, 13.80s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.934      0.838      0.935      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20         0G     0.6226     0.6176      1.055         20        640: 100%|██████████| 66/66 [15:08<00:00, 13.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.956      0.865      0.947      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20         0G     0.5915     0.5655      1.024         21        640: 100%|██████████| 66/66 [15:16<00:00, 13.89s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.947      0.842       0.94      0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20         0G     0.5692     0.5473      1.016         22        640: 100%|██████████| 66/66 [15:13<00:00, 13.84s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:51<00:00,  6.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.909      0.874      0.939      0.778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20         0G     0.5441     0.5226     0.9862         19        640: 100%|██████████| 66/66 [15:22<00:00, 13.98s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:50<00:00,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.921      0.888       0.94      0.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20         0G     0.5229      0.493      0.981         20        640: 100%|██████████| 66/66 [15:21<00:00, 13.97s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:52<00:00,  6.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.941      0.878      0.946      0.785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 5.355 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.155 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:47<00:00,  5.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        225        379      0.941      0.878      0.946      0.785\n",
            "               buffalo         62         89       0.97      0.865      0.952      0.808\n",
            "              elephant         53         91      0.871      0.857      0.922      0.761\n",
            "                 rhino         55         85      0.963      0.923      0.957      0.828\n",
            "                 zebra         59        114      0.959      0.868      0.955      0.742\n",
            "Speed: 2.1ms preprocess, 196.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "\n",
            "--- Training complete! ---\n",
            "Results initially saved locally to: /content/runs/detect/train\n",
            "Copying results to Google Drive: /content/drive/MyDrive/YOLOv8_African_Wildlife_Results/train...\n",
            "Results successfully copied to Google Drive!\n",
            "You can find your results (graphs, best.pt model, etc.) here: /content/drive/MyDrive/YOLOv8_African_Wildlife_Results/train\n",
            "\n",
            "--- Verifying dataset directory contents (/content/datasets/african-wildlife) ---\n",
            "total 12\n",
            "drwxr-xr-x 4 root root 4096 Jun 15 13:20 test\n",
            "drwxr-xr-x 4 root root 4096 Jun 15 13:20 train\n",
            "drwxr-xr-x 4 root root 4096 Jun 15 13:20 valid\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsf9dwn0vHeq",
        "outputId": "680cbf26-6ef9-46eb-b395-6f95d4ed82f0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}